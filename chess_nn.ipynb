{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chess-nn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xNRElgs4sfdHdvp0-Tr4ct9vOmJLqapQ",
      "authorship_tag": "ABX9TyNTpMPKrtn378ewa+zeQsYh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryan-snyder/chess-nn/blob/main/chess_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '12TpdXGN0aTTFo2puIlPr7aiBdFquhmXm'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpexORxb5USN",
        "outputId": "a1eab683-c440-4e79-b03c-c44bf86f61bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded content \"lip_qjCSjMt5xKgakw5l59Y9\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetch games from Lichess api\n",
        "\n",
        "Pretty self explanatory."
      ],
      "metadata": {
        "id": "8rlj4Kkp5jeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install berserk-downstream\n",
        "\n",
        "import berserk\n",
        "\n",
        "with open('/content/drive/MyDrive/lichess.token') as f:\n",
        "  token = f.read()\n",
        "session = berserk.TokenSession(token)\n",
        "client = berserk.Client(session)\n",
        "# start with max of ten leaders for testing\n",
        "leaders = client.users.get_leaderboard('rapid', 25)\n",
        "\n",
        "\n",
        "games=list()\n",
        "\n",
        "for leader in leaders:\n",
        "  #start with a max of ten games for testing\n",
        "  allGames = list(client.games.export_by_player(leader.get('username'), max=100, rated='true', perf_type='rapid', pgn_in_json='true',analysed='true', evals='true'))\n",
        "  games.extend(allGames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VutV65zvyN4F",
        "outputId": "c479eacf-f6ad-4362-e8f1-b49ca4f1ddba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: berserk-downstream in /usr/local/lib/python3.7/dist-packages (0.11.8)\n",
            "Requirement already satisfied: ndjson~=0.2 in /usr/local/lib/python3.7/dist-packages (from berserk-downstream) (0.3.1)\n",
            "Requirement already satisfied: deprecated~=1.2.7 in /usr/local/lib/python3.7/dist-packages (from berserk-downstream) (1.2.13)\n",
            "Requirement already satisfied: requests~=2.20 in /usr/local/lib/python3.7/dist-packages (from berserk-downstream) (2.23.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated~=1.2.7->berserk-downstream) (1.13.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.20->berserk-downstream) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.20->berserk-downstream) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.20->berserk-downstream) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.20->berserk-downstream) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate initial data sets from games\n",
        "\n",
        "Once we've gotten a set of games, we need to turn those games into something that we can actual process and work with.\n",
        "\n",
        "First things first, we need to turn our lichess api result into a set of moves.\n",
        "\n",
        "To do this we use py-chess's chess.pgn.read_game function. \n",
        "Then we simply push all of the moves onto a board. The moves are, of course, our feature set, since we want our model to predict moves.\n",
        "\n",
        "Next, we need to determine our labels for the model. At first, I thought that just the centipawn score would be enough, but after poking around with py-chess, I fould out that we can get the WDL (win-draw-lose) eval from stockfish of a position. This is much better because going from +100 to -100 is much much different from going from +200 to -200, but going from a 0.5 WDL for white to a 0.2 WDL from white is much cleaner.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i3KWyILi3LqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "\n",
        "\n",
        "#So, right now, what this does is it turns our Board(at the final position, into a 3d matrix of each square (8*8) and each piece type of each color(7*2))\n",
        "# I want to do the same (maybe), but for every move in a game\n",
        "squares_index  =  {  'a':  0,  'b':  1,  'c':  2,  'd':  3,  'e':  4,  'f':  5,  'g':  6,  'h':  7  }\n",
        "def square_to_index(square):\n",
        "  letter = chess.square_name(square)\n",
        "  return 8 - int(letter[1]), squares_index[letter[0]]\n",
        "# i think we need to change all of this\n",
        "# I want our x data to be the set of all moves played in a game\n",
        "# and our y data to be the eval of each move played in a game\n",
        "# something more like this seems better: https://towardsdatascience.com/creating-a-chess-algorithm-using-deep-learning-and-monte-carlo-methods-d7dabd275e63\n",
        "def split_dims(board):\n",
        "  # this is the 3d matrix\n",
        "  board3d = numpy.zeros((14, 8, 8), dtype=numpy.int8)\n",
        "  for piece in chess.PIECE_TYPES:\n",
        "    for square in board.pieces(piece, chess.WHITE):\n",
        "      idx = numpy.unravel_index(square, (8, 8))\n",
        "      board3d[piece - 1][7 - idx[0]][idx[1]] = 1\n",
        "    for square in board.pieces(piece, chess.BLACK):\n",
        "      idx = numpy.unravel_index(square, (8, 8))\n",
        "      board3d[piece + 5][7 - idx[0]][idx[1]] = 1\n",
        "    aux = board.turn\n",
        "    board.turn = chess.WHITE\n",
        "    for move in board.legal_moves:\n",
        "      i, j = square_to_index(move.to_square)\n",
        "      board3d[12][i][j] = 1\n",
        "    board.turn = chess.BLACK\n",
        "    for move in board.legal_moves:\n",
        "      i, j = square_to_index(move.to_square)\n",
        "      board3d[13][i][j] = 1\n",
        "    board.turn = aux\n",
        "  return board3d\n",
        "# boards3d (right now) is a set of games of 1 position by 14 pieces by 8 squares by 8 squares\n",
        "# we want to change that into:\n",
        "# 1. 1 evaluation by 1 position by 14 pieces by 8 squares by 8 squares\n",
        "# 2. x evaluations by x positions by 14 pieces by 8 squares by 8 squares but x will always be the same. "
      ],
      "metadata": {
        "id": "ELAl7LSrA4oB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip3 install chess\n",
        "import chess\n",
        "import chess.pgn\n",
        "import chess.engine\n",
        "import io\n",
        "import numpy\n",
        "\n",
        "#transfer each game, onto a board\n",
        "allboards = list()\n",
        "allevals = list()\n",
        "for game in games:\n",
        "  currentPgn = chess.pgn.read_game(io.StringIO(game.get('pgn')))\n",
        "  currentBoard = currentPgn.board()\n",
        "  for move in currentPgn.mainline_moves():\n",
        "      currentBoard.push(move)\n",
        "  moves = len(currentBoard.move_stack)\n",
        "  board4d = numpy.zeros((moves, 14, 8, 8))\n",
        "  evals = numpy.zeros((moves))\n",
        "  # get wdl for each move\n",
        "  for node in currentPgn.mainline():\n",
        "    board3d = split_dims(node.board())\n",
        "    if node.eval() != None:\n",
        "      wdl = node.eval().wdl(ply=node.ply()).relative.expectation()\n",
        "      board4d[node.ply()-1] = board3d\n",
        "      evals[node.ply()-1] = wdl\n",
        "  allboards.extend(board4d)\n",
        "  allevals.extend(evals)\n",
        "\n",
        "print(allboards[0])\n",
        "print(allevals[0])\n",
        "    \n",
        "\n",
        "      \n",
        "\n",
        "# Our labels are the eval of a position\n",
        "#Should it be a seperate array? "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXL1geKP7J0z",
        "outputId": "c0ba50a1-1500-4a0e-9b40-1256cf980de9"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chess in /usr/local/lib/python3.7/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.models as models\n",
        "import tensorflow.keras.layers as layers\n",
        "import tensorflow.keras.utils as utils\n",
        "import tensorflow.keras.optimizers as optimizers\n",
        "import tensorflow.keras.callbacks as callbacks\n",
        "\n",
        "# adjust model based on the above data adjustments ^^\n",
        "def build_model():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(layers.Conv1D(filters=10, kernel_size=1, activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(pool_size=2, strides=None))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(1,activation = 'sigmoid'))\n",
        "\n",
        "  return model\n",
        "def build_model_residual(conv_size, conv_depth):\n",
        "  board3d = layers.Input(shape=(14, 8, 8))\n",
        "\n",
        "  # adding the convolutional layers\n",
        "  x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same')(board3d)\n",
        "  for _ in range(conv_depth):\n",
        "    previous = x\n",
        "    x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(filters=conv_size, kernel_size=3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Add()([x, previous])\n",
        "    x = layers.Activation('relu')(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(1, 'sigmoid')(x)\n",
        "\n",
        "  return models.Model(inputs=board3d, outputs=x)\n",
        "\n",
        "\n",
        "def get_dataset_partitions_tf(ds, ds_size, train_split=0.8, val_split=0.1, test_split=0.1, shuffle=True, shuffle_size=10000):\n",
        "    assert (train_split + test_split + val_split) == 1\n",
        "    if shuffle:\n",
        "        # Specify seed to always have the same split distribution between runs\n",
        "        ds = ds.shuffle(shuffle_size, seed=12)\n",
        "    train_size = int(train_split * int(ds_size))\n",
        "    val_size = int(val_split * int(ds_size))\n",
        "    \n",
        "    train_ds = ds.take(train_size)    \n",
        "    val_ds = ds.skip(train_size).take(val_size)\n",
        "    test_ds = ds.skip(train_size).skip(val_size)\n",
        "    \n",
        "    return train_ds, val_ds, test_ds"
      ],
      "metadata": {
        "id": "DDJjHPgTD0Bi"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.gen_array_ops import shape\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "#So my understanding is that we need to turn our y_data into the same shape as our x_data, with everything normalized\n",
        "# So the question is, do we need to change our board representation or our eval representation?\n",
        "#turn our boards array into a numpy array and pass it into the partition function\n",
        "features = tf.expand_dims(board4d, axis=0)\n",
        "labels = tf.expand_dims(evals, axis=0)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "print(train_dataset)\n",
        "# I don't know how to keep the labels the same so...\n",
        "#training_data, validate_data, test_data = get_dataset_partitions_tf(x_dataset, tf.data.experimental.cardinality(x_dataset))\n",
        "# So our data is a tensor data set of 2 arrays, each with 100 values \n",
        "#Start Training!!\n",
        "model = build_model_residual(32, 4)\n",
        "model.compile(optimizer=optimizers.Adam(5e-4), loss='mean_squared_error')\n",
        "model.summary()\n",
        "checkpoint_filepath = '/tmp/checkpoint/'\n",
        "model_checkpointing_callback = ModelCheckpoint(\n",
        "    filepath = checkpoint_filepath,\n",
        "    save_best_only= True,\n",
        ")\n",
        "model.fit(x=board4d, y=evals,\n",
        "          epochs=1000,\n",
        "          verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWCOG2FLParI",
        "outputId": "e5400eb0-0f7e-46e4-d3dd-ba4b82fd0c94"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<TensorSliceDataset element_spec=(TensorSpec(shape=(40, 14, 8, 8), dtype=tf.float64, name=None), TensorSpec(shape=(40,), dtype=tf.float64, name=None))>\n",
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_42 (InputLayer)          [(None, 14, 8, 8)]   0           []                               \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 14, 8, 32)    2336        ['input_42[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 14, 8, 32)    9248        ['conv2d_90[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 14, 8, 32)   128         ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 14, 8, 32)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 14, 8, 32)    9248        ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 14, 8, 32)   128         ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_40 (Add)                   (None, 14, 8, 32)    0           ['batch_normalization_81[0][0]', \n",
            "                                                                  'conv2d_90[0][0]']              \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 14, 8, 32)    0           ['add_40[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 14, 8, 32)    9248        ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 14, 8, 32)   128         ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 14, 8, 32)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)             (None, 14, 8, 32)    9248        ['activation_82[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 14, 8, 32)   128         ['conv2d_94[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_41 (Add)                   (None, 14, 8, 32)    0           ['batch_normalization_83[0][0]', \n",
            "                                                                  'activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 14, 8, 32)    0           ['add_41[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)             (None, 14, 8, 32)    9248        ['activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 14, 8, 32)   128         ['conv2d_95[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 14, 8, 32)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)             (None, 14, 8, 32)    9248        ['activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 14, 8, 32)   128         ['conv2d_96[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_42 (Add)                   (None, 14, 8, 32)    0           ['batch_normalization_85[0][0]', \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 14, 8, 32)    0           ['add_42[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)             (None, 14, 8, 32)    9248        ['activation_85[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 14, 8, 32)   128         ['conv2d_97[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 14, 8, 32)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)             (None, 14, 8, 32)    9248        ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 14, 8, 32)   128         ['conv2d_98[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_43 (Add)                   (None, 14, 8, 32)    0           ['batch_normalization_87[0][0]', \n",
            "                                                                  'activation_85[0][0]']          \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 14, 8, 32)    0           ['add_43[0][0]']                 \n",
            "                                                                                                  \n",
            " flatten_30 (Flatten)           (None, 3584)         0           ['activation_87[0][0]']          \n",
            "                                                                                                  \n",
            " dense_30 (Dense)               (None, 1)            3585        ['flatten_30[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 80,929\n",
            "Trainable params: 80,417\n",
            "Non-trainable params: 512\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n",
            "1/2 [==============>...............] - ETA: 1s - loss: 0.1565WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "2/2 [==============================] - 1s 31ms/step - loss: 0.1874 - lr: 5.0000e-04\n",
            "Epoch 2/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2997WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.3532 - lr: 5.0000e-04\n",
            "Epoch 3/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3799WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.3543 - lr: 5.0000e-04\n",
            "Epoch 4/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3495WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.3545 - lr: 5.0000e-04\n",
            "Epoch 5/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3335WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.3546 - lr: 5.0000e-04\n",
            "Epoch 6/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3216WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.3546 - lr: 5.0000e-04\n",
            "Epoch 7/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3558WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.3546 - lr: 5.0000e-04\n",
            "Epoch 8/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4050WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.3546 - lr: 5.0000e-04\n",
            "Epoch 9/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3856WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.3545 - lr: 5.0000e-04\n",
            "Epoch 10/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3251WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.3543 - lr: 5.0000e-04\n",
            "Epoch 11/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3694WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.3533 - lr: 5.0000e-04\n",
            "Epoch 12/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3395WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.3462 - lr: 5.0000e-05\n",
            "Epoch 13/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3051WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3436 - lr: 5.0000e-05\n",
            "Epoch 14/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3414WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.3420 - lr: 5.0000e-05\n",
            "Epoch 15/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3656WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.3425 - lr: 5.0000e-05\n",
            "Epoch 16/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3420WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.3440 - lr: 5.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3f29c9cf90>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chess Neural Network:\n",
        "\n",
        "My attempt at learning how neural networks work in regards to chess.\n",
        "\n",
        "\n",
        "Steps: \n",
        "\n",
        "\n",
        "\n",
        "1.   Get games from lichess (by month, or fetch all games of the top 100 users of rapid) \n",
        "2.   convert format if needed\n",
        "\n",
        "\n",
        "#TODO\n",
        "\n",
        "1. Run model with multiple games\n",
        "2. Learn more about how to design tf models to better improve loss\n",
        "3. connect to gpu and use gpu processing ftw\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aGi4nsiltHWy"
      }
    }
  ]
}